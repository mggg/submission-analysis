{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d667b1-eebe-4b07-9555-7a6b070704e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ea071-31e2-4001-92f7-72b067bf5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = '../OHCumulativeAug10.csv'\n",
    "out_file = 'oh_noun_chunks.csv'\n",
    "filter_files = ('mi_filtered.csv', 'mo_filtered.csv', 'wi_filtered.csv')\n",
    "model = 'en_core_web_lg'\n",
    "text_col = ['text', 'title']\n",
    "min_count = 5\n",
    "nouns_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465eebc-0039-4375-837d-0c58927b4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_is_word(token):\n",
    "    \"\"\"Determines whether a token is a word.\"\"\"\n",
    "    # similar to: https://stackoverflow.com/a/41425016\n",
    "    return not token.is_stop and not token.is_punct and token.text.strip()\n",
    "\n",
    "def token_is_noun(token):\n",
    "    \"\"\"Determines whether a token is a noun.\"\"\"\n",
    "    return token_is_word(token) and token.pos_ == 'NOUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1181759-f233-4717-94a8-9e0792154a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(in_file)\n",
    "texts = []\n",
    "for col in text_col:\n",
    "    texts += list(df[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244416d-5b9b-499c-b0f8-26c70ff545b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e8c3e-2712-4464-89de-34527265ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "entities = []\n",
    "chunks = []\n",
    "filter_fn = token_is_noun if nouns_only else token_is_word\n",
    "for text in tqdm(texts):\n",
    "    raw_doc = nlp(text)\n",
    "    for ent in raw_doc.ents:\n",
    "        entities.append(ent)\n",
    "        text = text.replace(ent.text, '')\n",
    "    filtered_doc = nlp(text)\n",
    "    for chunk in filtered_doc.noun_chunks:\n",
    "      if not chunk.root.is_stop:\n",
    "        filtered_chunk = []\n",
    "        for token in chunk:\n",
    "          if filter_fn(token):\n",
    "            filtered_chunk.append(token.lemma_.lower())\n",
    "        if filtered_chunk:\n",
    "          chunks.append(' '.join(filtered_chunk))\n",
    "    for token in filtered_doc:\n",
    "        if filter_fn(token):\n",
    "            tokens.append(token.lemma_.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d55096-6467-4874-9153-02af45944434",
   "metadata": {},
   "outputs": [],
   "source": [
    "sieve = set()\n",
    "for filename in filter_files:\n",
    "  sieve |= set(pd.read_csv(filename)['chunk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b149f10-bfb3-4180-a5f0-c4ec0afb96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_counts = Counter(chunks)\n",
    "chunks_df = pd.DataFrame(\n",
    "  {'chunk': chunk, 'count': count}\n",
    "  for chunk, count in chunk_counts.most_common()\n",
    "  if count >= min_count\n",
    ")\n",
    "chunks_df = chunks_df[~chunks_df['chunk'].isin(sieve)]\n",
    "chunks_df.to_csv(out_file, index=False)\n",
    "chunks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb64c12-137c-4eda-8320-1ca3fbedea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter(tokens)\n",
    "tokens_df = pd.DataFrame({'token': tok, 'count': count} for tok, count in token_counts.most_common(250))\n",
    "tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bde8d9-d489-4a27-a939-7d7cc1586c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_counts = Counter([ent.text for ent in entities if ent.label_ == 'LOC'])\n",
    "entities_df = pd.DataFrame({'entity': entity, 'count': count} for entity, count in entity_counts.most_common(250))\n",
    "entities_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
